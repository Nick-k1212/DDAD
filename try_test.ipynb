{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 29\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     config \u001b[38;5;241m=\u001b[39m OmegaConf\u001b[38;5;241m.\u001b[39mload(args\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m     31\u001b[0m     checkpoint_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), config\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcheckpoint_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m, in \u001b[0;36mparse_args\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_args\u001b[39m():\n\u001b[0;32m     12\u001b[0m     cmdline_parser \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mArgumentParser(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDDAD\u001b[39m\u001b[38;5;124m'\u001b[39m)    \n\u001b[0;32m     13\u001b[0m     cmdline_parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-cfg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--config\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m---> 14\u001b[0m                                 default\u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m)),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m), \n\u001b[0;32m     15\u001b[0m                                 help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig file\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m     cmdline_parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--train\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     17\u001b[0m                                 default\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m#False\u001b[39;00m\n\u001b[0;32m     18\u001b[0m                                 help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain the diffusion model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m     cmdline_parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--detection\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     20\u001b[0m                                 default\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;66;03m#False\u001b[39;00m\n\u001b[0;32m     21\u001b[0m                                 help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDetection anomalies\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "from unet import *\n",
    "from omegaconf import OmegaConf\n",
    "from train import trainer\n",
    "from feature_extractor import * \n",
    "from ddad import *\n",
    "torch.cuda.empty_cache()\n",
    "def parse_args():\n",
    "    cmdline_parser = argparse.ArgumentParser('DDAD')    \n",
    "    cmdline_parser.add_argument('-cfg', '--config', \n",
    "                                default= os.path.join(os.path.dirname(os.path.abspath(__file__)),'config.yaml'), \n",
    "                                help='config file')\n",
    "    cmdline_parser.add_argument('--train', \n",
    "                                default= True, #False\n",
    "                                help='Train the diffusion model')\n",
    "    cmdline_parser.add_argument('--detection', \n",
    "                                default= True, #False\n",
    "                                help='Detection anomalies')\n",
    "    cmdline_parser.add_argument('--domain_adaptation', \n",
    "                                default= True, #False\n",
    "                                help='Domain adaptation')\n",
    "    args, unknowns = cmdline_parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    config = OmegaConf.load(args.config)\n",
    "    checkpoint_path = os.path.join(os.getcwd(), config.model.checkpoint_dir, \"model.pth\")\n",
    "    if not os.path.isfile(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint file not found: {checkpoint_path}\")\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\envs\\torch_gpu\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "from unet import *\n",
    "from omegaconf import OmegaConf\n",
    "from train import trainer\n",
    "from feature_extractor import * \n",
    "from ddad import *\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2\"\n",
    "\n",
    "def build_model(config):\n",
    "    if config.model.DDADS:\n",
    "        unet = UNetModel(config.data.image_size, 32, dropout=0.3, n_heads=2 ,in_channels=config.data.input_channel)\n",
    "    else:\n",
    "        unet = UNetModel(config.data.image_size, 64, dropout=0.0, n_heads=4 ,in_channels=config.data.input_channel)\n",
    "    return unet\n",
    "\n",
    "def train(config):\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    unet = build_model(config)\n",
    "    print(\" Num params: \", sum(p.numel() for p in unet.parameters()))\n",
    "    unet = unet.to(config.model.device)\n",
    "    unet.train()\n",
    "    unet = torch.nn.DataParallel(unet)\n",
    "    # checkpoint = torch.load(os.path.join(os.path.join(os.getcwd(), config.model.checkpoint_dir), config.data.category,'1000'))\n",
    "    # unet.load_state_dict(checkpoint)  \n",
    "    trainer(unet, config.data.category, config)#config.data.category, \n",
    "\n",
    "\n",
    "def detection(config):\n",
    "    unet = build_model(config)\n",
    "    checkpoint = torch.load(os.path.join(os.getcwd(), config.model.checkpoint_dir, config.data.category, str(config.model.load_chp)))\n",
    "    unet = torch.nn.DataParallel(unet)\n",
    "    unet.load_state_dict(checkpoint)    \n",
    "    unet.to(config.model.device)\n",
    "    checkpoint = torch.load(os.path.join(os.getcwd(), config.model.checkpoint_dir, config.data.category, str(config.model.load_chp)))\n",
    "    unet.eval()\n",
    "    ddad = DDAD(unet, config)\n",
    "    ddad()\n",
    "    \n",
    "\n",
    "def finetuning(config):\n",
    "    unet = build_model(config)\n",
    "    checkpoint = torch.load(os.path.join(os.getcwd(), config.model.checkpoint_dir, config.data.category, str(config.model.load_chp)))\n",
    "    unet = torch.nn.DataParallel(unet)\n",
    "    unet.load_state_dict(checkpoint)    \n",
    "    unet.to(config.model.device)\n",
    "    unet.eval()\n",
    "    domain_adaptation(unet, config, fine_tune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 85\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     84\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m---> 85\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     config \u001b[38;5;241m=\u001b[39m OmegaConf\u001b[38;5;241m.\u001b[39mload(args\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcategory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, w: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, v: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_chp: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_chp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, feature extractor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfeature_extractor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw_DA: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mw_DA\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, DLlambda: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mDLlambda\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 75\u001b[0m, in \u001b[0;36mparse_args\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse command-line arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m parser \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mArgumentParser(description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDDAD Pipeline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     74\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-cfg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--config\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m---> 75\u001b[0m                     default\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     76\u001b[0m                     help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPath to the configuration file.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     77\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--train\u001b[39m\u001b[38;5;124m'\u001b[39m, action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_true\u001b[39m\u001b[38;5;124m'\u001b[39m, help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain the model.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     78\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--detection\u001b[39m\u001b[38;5;124m'\u001b[39m, action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_true\u001b[39m\u001b[38;5;124m'\u001b[39m, help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerform anomaly detection.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "from unet import UNetModel\n",
    "from train import trainer\n",
    "from ddad import DDAD, domain_adaptation\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2\"\n",
    "\n",
    "\n",
    "def build_model(config):\n",
    "    \"\"\"Build UNet model based on the configuration.\"\"\"\n",
    "    in_channels = config.data.input_channel\n",
    "    if config.model.DDADS:\n",
    "        return UNetModel(config.data.image_size, 32, dropout=0.3, n_heads=2, in_channels=in_channels)\n",
    "    else:\n",
    "        return UNetModel(config.data.image_size, 64, dropout=0.0, n_heads=4, in_channels=in_channels)\n",
    "\n",
    "\n",
    "def train(config):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    torch.manual_seed(config.model.seed)\n",
    "    np.random.seed(config.model.seed)\n",
    "\n",
    "    unet = build_model(config)\n",
    "    print(\"Number of parameters:\", sum(p.numel() for p in unet.parameters()))\n",
    "    unet = unet.to(config.model.device)\n",
    "    unet.train()\n",
    "    unet = torch.nn.DataParallel(unet)\n",
    "\n",
    "    trainer(unet, config.data.category, config)\n",
    "\n",
    "\n",
    "def detection(config):\n",
    "    \"\"\"Detect anomalies using a pre-trained model.\"\"\"\n",
    "    unet = build_model(config)\n",
    "    checkpoint_path = os.path.join(config.model.checkpoint_dir, config.data.category, str(config.model.load_chp))\n",
    "\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found at {checkpoint_path}\")\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    unet = torch.nn.DataParallel(unet)\n",
    "    unet.load_state_dict(checkpoint)\n",
    "    unet.to(config.model.device)\n",
    "    unet.eval()\n",
    "\n",
    "    ddad = DDAD(unet, config)\n",
    "    ddad()\n",
    "\n",
    "\n",
    "def finetuning(config):\n",
    "    \"\"\"Fine-tune the model for domain adaptation.\"\"\"\n",
    "    unet = build_model(config)\n",
    "    checkpoint_path = os.path.join(config.model.checkpoint_dir, config.data.category, str(config.model.load_chp))\n",
    "\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint not found at {checkpoint_path}\")\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    unet = torch.nn.DataParallel(unet)\n",
    "    unet.load_state_dict(checkpoint)\n",
    "    unet.to(config.model.device)\n",
    "    unet.eval()\n",
    "\n",
    "    domain_adaptation(unet, config, fine_tune=True)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"Parse command-line arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='DDAD Pipeline')\n",
    "    parser.add_argument('-cfg', '--config',\n",
    "                        default=os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.yaml'),\n",
    "                        help='Path to the configuration file.')\n",
    "    parser.add_argument('--train', action='store_true', help='Train the model.')\n",
    "    parser.add_argument('--detection', action='store_true', help='Perform anomaly detection.')\n",
    "    parser.add_argument('--domain_adaptation', action='store_true', help='Perform domain adaptation.')\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.cuda.empty_cache()\n",
    "    args = parse_args()\n",
    "    config = OmegaConf.load(args.config)\n",
    "\n",
    "    print(f\"Class: {config.data.category}, w: {config.model.w}, v: {config.model.v}, \"\n",
    "          f\"load_chp: {config.model.load_chp}, feature extractor: {config.model.feature_extractor}, \"\n",
    "          f\"w_DA: {config.model.w_DA}, DLlambda: {config.model.DLlambda}\")\n",
    "\n",
    "    torch.manual_seed(config.model.seed)\n",
    "    np.random.seed(config.model.seed)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(config.model.seed)\n",
    "\n",
    "    if args.train:\n",
    "        print('Training...')\n",
    "        train(config)\n",
    "\n",
    "    if args.domain_adaptation:\n",
    "        print('Domain Adaptation...')\n",
    "        finetuning(config)\n",
    "\n",
    "    if args.detection:\n",
    "        print('Detecting Anomalies...')\n",
    "        detection(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
